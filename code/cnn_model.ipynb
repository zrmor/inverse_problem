{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from models import CNNClassifier, MatrixDataset, get_feature_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = \"../data/\"\n",
    "all_C = np.load(data_path + 'all_C.npy') # 1329 input matrices of size 30x30\n",
    "nMF_label = np.load(data_path + 'nMF_label.npy') # 1329 output labels (0 or 1)\n",
    "\n",
    "class_0_C = all_C[nMF_label == 0] # input matrices of size 30x30 with nMF label 0\n",
    "class_1_C = all_C[nMF_label == 1] # input matrices of size 30x30 with nMF label 1\n",
    "\n",
    "# print some stats\n",
    "print(f\"Number of input matrices with nMF label 0: {class_0_C.shape[0]}\")\n",
    "print(f\"Number of input matrices with nMF label 1: {class_1_C.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the normality of the data\n",
    "non_normal_indices = []\n",
    "\n",
    "# Test each matrix individually\n",
    "for i in range(len(all_C)):\n",
    "    # Flatten current matrix\n",
    "    matrix_flat = all_C[i].flatten()\n",
    "    \n",
    "    # Perform normality test\n",
    "    _, p_value = stats.normaltest(matrix_flat)\n",
    "    \n",
    "    # If p-value <= 0.05, the distribution is not normal\n",
    "    if p_value <= 0.05:\n",
    "        non_normal_indices.append(i)\n",
    "\n",
    "# Print results\n",
    "if len(non_normal_indices) == 0:\n",
    "    print(\"Normality check passed: All matrices are normally distributed\")\n",
    "else:\n",
    "    print(f\"Normality check failed: {len(non_normal_indices)} out of {len(all_C)} matrices are not normally distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the matrices\n",
    "plt.figure(figsize=(25, 20))\n",
    "\n",
    "# Plot 10 random matrices from class 0 \n",
    "for i in range(10):\n",
    "    row = i // 5  # 0 for first 5 items, 1 for next 5\n",
    "    col = i % 5   # 0-4 for each row\n",
    "    plt.subplot(4, 5, row*5 + col + 1)\n",
    "    random_idx = np.random.randint(0, len(class_0_C))\n",
    "    im = plt.imshow(class_0_C[random_idx], cmap='viridis')\n",
    "    plt.title(f'Class 0\\nSample {random_idx}')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot 10 random matrices from class 1 \n",
    "for i in range(10):\n",
    "    row = i // 5  # 0 for first 5 items, 1 for next 5\n",
    "    col = i % 5   # 0-4 for each row\n",
    "    plt.subplot(4, 5, (row+2)*5 + col + 1)  # +2 to start from third row\n",
    "    random_idx = np.random.randint(0, len(class_1_C))\n",
    "    im = plt.imshow(class_1_C[random_idx], cmap='viridis')\n",
    "    plt.title(f'Class 1\\nSample {random_idx}')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Add a main title\n",
    "plt.suptitle('Random Samples of Correlation Matrices from Both Classes', \n",
    "             fontsize=16, y=1.02)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min and max for each matrix\n",
    "mins = np.array([matrix.min() for matrix in all_C])\n",
    "maxs = np.array([matrix.max() for matrix in all_C])\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Plot of all data\n",
    "plt.subplot(321)\n",
    "plt.boxplot([mins, maxs], labels=['Min Values', 'Max Values'])\n",
    "plt.title('All Data: Distribution of Min/Max Values')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.subplot(322)\n",
    "sns.kdeplot(data=mins, label='Min Values', fill=True, alpha=0.3)\n",
    "sns.kdeplot(data=maxs, label='Max Values', fill=True, alpha=0.3)\n",
    "plt.title('All Data: Density Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "# Plots for each class\n",
    "for idx, class_label in enumerate([0, 1]):\n",
    "    class_indices = np.where(nMF_label == class_label)[0]\n",
    "    class_mins = mins[class_indices]\n",
    "    class_maxs = maxs[class_indices]\n",
    "    \n",
    "    # Box plot for class\n",
    "    plt.subplot(323 + idx*2)\n",
    "    plt.boxplot([class_mins, class_maxs], labels=['Min Values', 'Max Values'])\n",
    "    plt.title(f'Class {class_label}: Distribution of Min/Max Values')\n",
    "    plt.ylabel('Value')\n",
    "    \n",
    "    # Density plot for class\n",
    "    plt.subplot(324 + idx*2)\n",
    "    sns.kdeplot(data=class_mins, label='Min Values', fill=True, alpha=0.3)\n",
    "    sns.kdeplot(data=class_maxs, label='Max Values', fill=True, alpha=0.3)\n",
    "    plt.title(f'Class {class_label}: Density Distribution')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics for all data and by class\n",
    "print(\"Overall Statistics:\")\n",
    "print(\"\\nMinimum values:\")\n",
    "print(f\"Mean: {np.mean(mins):.4f}, Std: {np.std(mins):.4f}\")\n",
    "print(f\"Range: [{np.min(mins):.4f}, {np.max(mins):.4f}]\")\n",
    "\n",
    "print(\"\\nMaximum values:\")\n",
    "print(f\"Mean: {np.mean(maxs):.4f}, Std: {np.std(maxs):.4f}\")\n",
    "print(f\"Range: [{np.min(maxs):.4f}, {np.max(maxs):.4f}]\")\n",
    "\n",
    "# Print statistics by class\n",
    "for class_label in [0, 1]:\n",
    "    class_indices = np.where(nMF_label == class_label)[0]\n",
    "    class_mins = mins[class_indices]\n",
    "    class_maxs = maxs[class_indices]\n",
    "    \n",
    "    print(f\"\\nClass {class_label} Statistics:\")\n",
    "    print(f\"Number of samples: {len(class_indices)}\")\n",
    "    print(\"\\nMinimum values:\")\n",
    "    print(f\"Mean: {np.mean(class_mins):.4f}, Std: {np.std(class_mins):.4f}\")\n",
    "    print(f\"Range: [{np.min(class_mins):.4f}, {np.max(class_mins):.4f}]\")\n",
    "    \n",
    "    print(\"\\nMaximum values:\")\n",
    "    print(f\"Mean: {np.mean(class_maxs):.4f}, Std: {np.std(class_maxs):.4f}\")\n",
    "    print(f\"Range: [{np.min(class_maxs):.4f}, {np.max(class_maxs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get my API key from environment variable first\n",
    "wandb_key = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "# If not found in environment, prompt user\n",
    "if not wandb_key:\n",
    "    wandb_key = getpass(\"Enter your Weights & Biases API key: \")\n",
    "\n",
    "wandb.login(key=wandb_key)\n",
    "\n",
    "# First split into train+val and test sets (80-20 split)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    all_C, nMF_label, test_size=0.2, random_state=42, stratify=nMF_label\n",
    ")\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-3],\n",
    "    'conv_channels': [[1, 16, 32, 64]],\n",
    "    'dropout_rate': [0.5],\n",
    "    'batch_size': [32]\n",
    "}\n",
    "\n",
    "# K-fold setup for cross-validation on training data\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search with k-fold cross validation\n",
    "best_val_acc = 0\n",
    "best_params = None\n",
    "\n",
    "print(\"Data split sizes:\")\n",
    "print(f\"Train + Validation: {len(X_trainval)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\\n\")\n",
    "\n",
    "print(\"Starting grid search with k-fold cross validation\")\n",
    "print(f\"Parameter grid:\\n{param_grid}\")\n",
    "print(f\"Number of folds: {kfold.n_splits}\\n\")\n",
    "\n",
    "# Grid search\n",
    "for lr in param_grid['learning_rate']:\n",
    "    for conv_ch in param_grid['conv_channels']:\n",
    "        for dropout in param_grid['dropout_rate']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(f\"Training with parameters:\")\n",
    "                print(f\"Learning rate: {lr}\")\n",
    "                print(f\"Conv channels: {conv_ch}\")\n",
    "                print(f\"Dropout rate: {dropout}\")\n",
    "                print(f\"Batch size: {batch_size}\\n\")\n",
    "\n",
    "                fold_scores = []\n",
    "                \n",
    "                # Initialize a new wandb run for this parameter combination\n",
    "                run = wandb.init(\n",
    "                    project=\"inverse_problem\",\n",
    "                    config={\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"conv_channels\": conv_ch,\n",
    "                        \"dropout_rate\": dropout,\n",
    "                        \"batch_size\": batch_size\n",
    "                    },\n",
    "                    reinit=True\n",
    "                )\n",
    "                \n",
    "                # K-fold cross validation\n",
    "                for fold, (train_idx, val_idx) in enumerate(kfold.split(X_trainval)):\n",
    "                    print(f\"\\nFold {fold+1}/{kfold.n_splits}\")\n",
    "                    print(f\"Train size: {len(train_idx)}, Validation size: {len(val_idx)}\")\n",
    "                    \n",
    "                    # Prepare data for this fold\n",
    "                    X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
    "                    y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
    "                    \n",
    "                    train_dataset = MatrixDataset(X_train, y_train)\n",
    "                    val_dataset = MatrixDataset(X_val, y_val)\n",
    "                    \n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                    \n",
    "                    # Initialize model and trainer\n",
    "                    model = CNNClassifier(\n",
    "                        learning_rate=lr,\n",
    "                        conv_channels=conv_ch,\n",
    "                        dropout_rate=dropout\n",
    "                    )\n",
    "                    \n",
    "                    checkpoint_callback = ModelCheckpoint(\n",
    "                        monitor='val_acc',\n",
    "                        dirpath='checkpoints',\n",
    "                        filename=f'fold_{fold}',\n",
    "                        save_top_k=1,\n",
    "                        mode='max'\n",
    "                    )\n",
    "                    \n",
    "                    trainer = pl.Trainer(\n",
    "                        max_epochs=50,\n",
    "                        logger=WandbLogger(project=\"inverse_problem\"),\n",
    "                        callbacks=[checkpoint_callback],\n",
    "                        accelerator='auto'\n",
    "                    )\n",
    "\n",
    "                    # Train model\n",
    "                    print(\"Training model...\")\n",
    "                    trainer.fit(model, train_loader, val_loader)\n",
    "                    \n",
    "                    fold_score = checkpoint_callback.best_model_score.item()\n",
    "                    fold_scores.append(fold_score)\n",
    "                    print(f\"Fold {fold+1} best validation accuracy: {fold_score:.4f}\")\n",
    "                \n",
    "                # Calculate average score for this parameter combination\n",
    "                avg_score = np.mean(fold_scores)\n",
    "                print(\"\\nResults for current parameters:\")\n",
    "                print(f\"Average validation accuracy: {avg_score:.4f}\")\n",
    "                print(f\"Standard deviation: {np.std(fold_scores):.4f}\")\n",
    "                \n",
    "                # Update best parameters if necessary\n",
    "                if avg_score > best_val_acc:\n",
    "                    best_val_acc = avg_score\n",
    "                    best_params = {\n",
    "                        'learning_rate': lr,\n",
    "                        'conv_channels': conv_ch,\n",
    "                        'dropout_rate': dropout,\n",
    "                        'batch_size': batch_size\n",
    "                    }\n",
    "                    print(\"\\nðŸŒŸ New best model found!\")\n",
    "                    print(f\"Best validation accuracy so far: {best_val_acc:.4f}\")\n",
    "                \n",
    "                wandb.finish()\n",
    "                print(\"\\nFinished wandb run\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Grid search completed!\")\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(f\"Learning rate: {best_params['learning_rate']}\")\n",
    "print(f\"Conv channels: {best_params['conv_channels']}\")\n",
    "print(f\"Dropout rate: {best_params['dropout_rate']}\")\n",
    "print(f\"Batch size: {best_params['batch_size']}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "# Train final model with best parameters on all training data\n",
    "print(\"\\nTraining final model with best parameters...\")\n",
    "final_train_dataset = MatrixDataset(X_trainval, y_trainval)\n",
    "final_test_dataset = MatrixDataset(X_test, y_test)\n",
    "\n",
    "final_train_loader = DataLoader(final_train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "final_test_loader = DataLoader(final_test_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "final_model = CNNClassifier(\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    conv_channels=best_params['conv_channels'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")\n",
    "\n",
    "final_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='checkpoints',\n",
    "    filename='final_model',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "final_trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=WandbLogger(project=\"inverse_problem\"),\n",
    "    callbacks=[final_checkpoint_callback],\n",
    "    accelerator='auto'\n",
    ")\n",
    "\n",
    "# Train the final model\n",
    "final_trainer.fit(final_model, final_train_loader)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = final_trainer.test(final_model, final_test_loader)\n",
    "print(f\"\\nFinal test accuracy: {test_results[0]['test_acc']:.4f}\")\n",
    "\n",
    "# Save the best model path\n",
    "best_model_path = final_checkpoint_callback.best_model_path\n",
    "print(f\"\\nBest model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature map visualization\n",
    "def visualize_feature_maps(feature_maps, sample_idx=0):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (name, features) in enumerate(feature_maps.items()):\n",
    "        # Get the first sample's feature maps\n",
    "        feature_map = features[sample_idx].cpu().numpy()\n",
    "        \n",
    "        # Create subplot for each conv layer\n",
    "        n_features = min(4, feature_map.shape[0])  # Show up to 4 features\n",
    "        for j in range(n_features):\n",
    "            plt.subplot(len(feature_maps), 4, i*4 + j + 1)\n",
    "            plt.imshow(feature_map[j], cmap='viridis')\n",
    "            plt.axis('off')\n",
    "            if j == 0:\n",
    "                plt.title(f'{name}\\nChannel {j}')\n",
    "            else:\n",
    "                plt.title(f'Channel {j}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load best model and get feature maps\n",
    "best_model = CNNClassifier.load_from_checkpoint('checkpoints/best_model.ckpt')\n",
    "sample_input = torch.FloatTensor(all_C[:1]).unsqueeze(1)  # Get first sample\n",
    "feature_maps = get_feature_maps(best_model, sample_input)\n",
    "visualize_feature_maps(feature_maps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse_problem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
